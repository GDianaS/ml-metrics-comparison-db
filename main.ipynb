{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configura√ß√£o Banco de Dados ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Conex√£o com o Banco de Dados ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine, text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [],
   "source": [
    "USER = \"your_user\"\n",
    "PASSWORD = \"your_password\"\n",
    "HOST = \"localhost\"\n",
    "DATABASE = \"your_database\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar conex√£o usando SQLAlchemy\n",
    "engine = create_engine(f\"mysql+pymysql://{USER}:{PASSWORD}@{HOST}/{DATABASE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cria√ß√£o das Tabelas ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deletar tabelas do bancos de dados\n",
    "with engine.connect() as connection:\n",
    "    tables_to_drop = [\"Metrics\", \"Experiments\", \"LearnStrategies\", \"Hyperparameters\", \"Models\"]\n",
    "    for table in tables_to_drop:\n",
    "        connection.execute(text(f\"DROP TABLE IF EXISTS {table};\"))\n",
    "    connection.commit() # Confirma a remo√ß√£o das tabelas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = {\n",
    "    \"Models\": \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS Models (\n",
    "        id INT AUTO_INCREMENT PRIMARY KEY,\n",
    "        type INT,  -- 0: Classifica√ß√£o, 1: Regress√£o\n",
    "        algorithm VARCHAR(50)\n",
    "    )\n",
    "    \"\"\",\n",
    "    \n",
    "    \"Hyperparameters\": \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS Hyperparameters (\n",
    "        id INT AUTO_INCREMENT PRIMARY KEY,\n",
    "        model_id INT,\n",
    "        name VARCHAR(50),\n",
    "        value VARCHAR(50),\n",
    "        FOREIGN KEY (model_id) REFERENCES Models(id) ON DELETE CASCADE\n",
    "    )\n",
    "    \"\"\",\n",
    "    \n",
    "    \"LearnStrategies\": \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS LearnStrategies (\n",
    "        id INT AUTO_INCREMENT PRIMARY KEY,\n",
    "        model_id INT NOT NULL,\n",
    "        preprocessing_type VARCHAR(50) NOT NULL,  -- Scaling, Sampling, Feature Selection\n",
    "        data_sampling VARCHAR(50) NOT NULL,  -- Undersampling, Oversampling, Stratified Sampling\n",
    "        type VARCHAR(50) NOT NULL,  -- Cross-Validation, Hold-out\n",
    "        len_data JSON NOT NULL,  -- Lista [Treino, Teste, Valida√ß√£o]\n",
    "        FOREIGN KEY (model_id) REFERENCES Models(id) ON DELETE CASCADE\n",
    "    )\n",
    "    \"\"\",\n",
    "    \n",
    "    \"Experiments\": \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS Experiments (\n",
    "        id INT AUTO_INCREMENT PRIMARY KEY,\n",
    "        model_id INT,\n",
    "        dataset VARCHAR(50),\n",
    "        date_created TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
    "        FOREIGN KEY (model_id) REFERENCES Models(id) ON DELETE CASCADE\n",
    "    )\n",
    "    \"\"\",\n",
    "\n",
    "    \"Metrics\": \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS Metrics (\n",
    "        id INT AUTO_INCREMENT PRIMARY KEY,\n",
    "        experiment_id INT,\n",
    "        type VARCHAR(50),\n",
    "        value FLOAT,\n",
    "        FOREIGN KEY (experiment_id) REFERENCES Experiments(id) ON DELETE CASCADE\n",
    "    )\n",
    "    \"\"\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabela Models criada com sucesso! ‚úÖ\n",
      "Tabela Hyperparameters criada com sucesso! ‚úÖ\n",
      "Tabela LearnStrategies criada com sucesso! ‚úÖ\n",
      "Tabela Experiments criada com sucesso! ‚úÖ\n",
      "Tabela Metrics criada com sucesso! ‚úÖ\n",
      "Todas as tabelas foram criadas corretamente! üéâ\n"
     ]
    }
   ],
   "source": [
    "with engine.connect() as connection:\n",
    "    for table_name, sql_query in tables.items():\n",
    "        connection.execute(text(sql_query)) # Use text() here!\n",
    "        print(f\"Tabela {table_name} criada com sucesso! ‚úÖ\")\n",
    "\n",
    "print(\"Todas as tabelas foram criadas corretamente! üéâ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.Fun√ß√µes de Treinamento e Avalia√ß√£o ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importa√ß√£o das Bibliotecas ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, LogisticRegression\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, mean_squared_error, mean_absolute_error, r2_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import KFold, cross_val_score, cross_val_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carregar Datasets ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(name):\n",
    "    from sklearn.datasets import load_iris, load_breast_cancer, load_diabetes, fetch_california_housing\n",
    "    \n",
    "    if name == \"iris\":\n",
    "        data = load_iris()\n",
    "    elif name == \"breast_cancer\":\n",
    "        data = load_breast_cancer()\n",
    "    elif name == \"diabetes\":\n",
    "        from sklearn.datasets import load_diabetes \n",
    "        data = load_diabetes()\n",
    "    elif name == \"california\":\n",
    "        data = fetch_california_housing()\n",
    "    else:\n",
    "        raise ValueError(\"Dataset n√£o suportado\")\n",
    "    \n",
    "    return pd.DataFrame(data.data, columns=data.feature_names), pd.Series(data.target)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fun√ß√£o de Treinamento e Salvamento no BD ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_save_model(dataset_name, model_type, algorithm, model, params={}, use_cross_val=False, test_size=0.2, val_size=0.0, cv=5, scaling = True, oversample=False, feature_selection=False, k=10):\n",
    "\n",
    "    try:  # Try to load the dataset, handle potential errors\n",
    "        X, y = load_dataset(dataset_name)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading dataset {dataset_name}: {e}\")\n",
    "        return  # Exit the function if dataset loading fails\n",
    "\n",
    "    scaling_applied = False\n",
    "    sampling_applied = False\n",
    "    feature_selection_applied = False\n",
    "\n",
    "    X_transformed = X  # Initialize X_transformed (will hold scaled or original data)\n",
    "\n",
    "    if scaling:  # Apply scaling if scaling is True\n",
    "        scaler = StandardScaler()\n",
    "        X_scaled = scaler.fit_transform(X)\n",
    "        X_transformed = X_scaled\n",
    "        scaling_applied = True\n",
    "\n",
    "    # Apply oversampling *before* splitting\n",
    "    try:  # Handle potential errors during oversampling\n",
    "        if oversample:\n",
    "            smote = SMOTE(random_state=42)\n",
    "            X_transformed, y = smote.fit_resample(X_transformed, y)  # Oversample all data\n",
    "            sampling_applied = True  # Set flag *after* successful oversampling\n",
    "    except ImportError:\n",
    "        print(\"imblearn not found. Install it using: pip install imbalanced-learn\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error during oversampling: {e}\")\n",
    "\n",
    "    # Apply feature selection *before* splitting\n",
    "    try:  # Handle potential errors during feature selection\n",
    "        if feature_selection:\n",
    "            n_features = X_transformed.shape[1]  # Get the number of features\n",
    "            k = min(k, n_features)  # Ensure k is not greater than n_features\n",
    "            selector = SelectKBest(f_classif, k=k)\n",
    "            X_transformed = selector.fit_transform(X_transformed, y)  # Fit and transform all data\n",
    "            feature_selection_applied = True  # Set flag *after* successful feature selection\n",
    "    except ImportError:\n",
    "        print(\"scikit-learn is required for feature selection.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error during feature selection: {e}\")\n",
    "\n",
    "\n",
    "    preprocessing_strategies = []\n",
    "\n",
    "    if scaling_applied:  # Check scaling_applied\n",
    "        preprocessing_strategies.append(\"Scaling\")\n",
    "    if sampling_applied:  # Check oversample directly\n",
    "        preprocessing_strategies.append(\"Sampling\")\n",
    "    if feature_selection_applied:  # Check feature_selection directly\n",
    "        preprocessing_strategies.append(\"Feature Selection\")\n",
    "\n",
    "    metrics = {}\n",
    "\n",
    "    if use_cross_val:\n",
    "        kfold = KFold(n_splits=cv, shuffle=True, random_state=42)\n",
    "        len_data = [cv, 0, 0]\n",
    "\n",
    "        if model_type == \"classification\":\n",
    "            y_pred = cross_val_predict(model, X_transformed, y, cv=kfold, method=\"predict\")\n",
    "\n",
    "            try: # Try to get probabilities; handle multi-class cases\n",
    "                y_prob = cross_val_predict(model, X_transformed, y, cv=kfold, method=\"predict_proba\")\n",
    "                if y_prob.shape[1] > 2: # Multi-class\n",
    "                    auc_roc = roc_auc_score(y, y_prob, multi_class='ovr', average='weighted')\n",
    "                else: # Binary class\n",
    "                    auc_roc = roc_auc_score(y, y_prob[:, 1], multi_class='ovr', average='weighted')\n",
    "            except AttributeError: # Model doesn't have predict_proba\n",
    "                auc_roc = None\n",
    "\n",
    "            metrics = {\n",
    "                \"accuracy\": accuracy_score(y, y_pred),\n",
    "                \"precision\": precision_score(y, y_pred, average='weighted'),\n",
    "                \"recall\": recall_score(y, y_pred, average='weighted'),\n",
    "                \"f1_score\": f1_score(y, y_pred, average='weighted'),\n",
    "                \"auc_roc\": auc_roc\n",
    "            }\n",
    "        else:  # Regression\n",
    "            y_pred = cross_val_predict(model, X_transformed, y, cv=kfold)\n",
    "            metrics = {\n",
    "                \"mse\": mean_squared_error(y, y_pred),\n",
    "                \"rmse\": np.sqrt(mean_squared_error(y, y_pred)),\n",
    "                \"mae\": mean_absolute_error(y, y_pred),\n",
    "                \"r2\": r2_score(y, y_pred)\n",
    "            }\n",
    "\n",
    "    else:\n",
    "        # Separar treino, teste e valida√ß√£o *after* oversampling and feature selection\n",
    "        if val_size > 0:\n",
    "            X_train, X_temp, y_train, y_temp = train_test_split(X_transformed, y, test_size=test_size, random_state=42)\n",
    "            X_test, X_val, y_test, y_val = train_test_split(X_temp, y_temp, test_size=test_size, random_state=42)\n",
    "            len_data = [len(X_train) / len(X_transformed), len(X_test) / len(X_transformed), len(X_val) / len(X_transformed)]\n",
    "        else:\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X_transformed, y, test_size=test_size, random_state=42)\n",
    "            len_data = [len(X_train) / len(X_transformed), len(X_test) / len(X_transformed), 0]\n",
    "\n",
    "        model.set_params(**params)\n",
    "        model.fit(X_train, y_train)  # Fit on the training data (no need for X_train_resampled)\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        if model_type == \"classification\":\n",
    "            metrics = {\n",
    "                \"accuracy\": accuracy_score(y_test, y_pred),\n",
    "                \"precision\": precision_score(y_test, y_pred, average='weighted'),\n",
    "                \"recall\": recall_score(y_test, y_pred, average='weighted'),\n",
    "                \"f1_score\": f1_score(y_test, y_pred, average='weighted'),\n",
    "                \"auc_roc\": roc_auc_score(y_test, model.predict_proba(X_test), multi_class='ovr', average='weighted') if hasattr(model, \"predict_proba\") else None\n",
    "            }\n",
    "        else:  # Regression\n",
    "            metrics = {\n",
    "                \"mse\": mean_squared_error(y_test, y_pred),\n",
    "                \"rmse\": np.sqrt(mean_squared_error(y_test, y_pred)),\n",
    "                \"mae\": mean_absolute_error(y_test, y_pred),\n",
    "                \"r2\": r2_score(y_test, y_pred)\n",
    "            }\n",
    "\n",
    "\n",
    "    with engine.connect() as connection:\n",
    "        try:\n",
    "            # Salvar model\n",
    "            result = connection.execute(text(\"INSERT INTO Models (type, algorithm) VALUES (:type, :algorithm)\"),\n",
    "                                        {\"type\": 0 if model_type == \"classification\" else 1, \"algorithm\": algorithm})\n",
    "            model_id = result.lastrowid\n",
    "\n",
    "            # Salvar hyperparameters\n",
    "            for name, value in params.items():\n",
    "                connection.execute(text(\"INSERT INTO Hyperparameters (model_id, name, value) VALUES (:model_id, :name, :value)\"),\n",
    "                                 {\"model_id\": model_id, \"name\": name, \"value\": str(value)})\n",
    "\n",
    "            # Salvar experiment\n",
    "            result = connection.execute(text(\"INSERT INTO Experiments (model_id, dataset) VALUES (:model_id, :dataset)\"),\n",
    "                                        {\"model_id\": model_id, \"dataset\": dataset_name})\n",
    "            experiment_id = result.lastrowid\n",
    "\n",
    "            # Salvar metrics\n",
    "            for metric, value in metrics.items():\n",
    "                connection.execute(text(\"INSERT INTO Metrics (experiment_id, type, value) VALUES (:experiment_id, :type, :value)\"),\n",
    "                             {\"experiment_id\": experiment_id, \"type\": metric, \"value\": value})\n",
    "\n",
    "            # Salvar LearnStrategies\n",
    "            result = connection.execute(text(\"INSERT INTO LearnStrategies (model_id, preprocessing_type, data_sampling, type, len_data) VALUES (:model_id, :preprocessing_type, :data_sampling, :type, :len_data)\"),\n",
    "                            {\"model_id\": model_id, \"preprocessing_type\": \", \".join(preprocessing_strategies), \"data_sampling\": \"None\", \"type\": \"Cross-Validation\" if use_cross_val else \"Hold-out\", \"len_data\": json.dumps(len_data)})\n",
    "\n",
    "            connection.commit()\n",
    "            print(f\"Modelo {algorithm} treinado e salvo com sucesso!\")\n",
    "\n",
    "        except Exception as e:\n",
    "            connection.rollback()\n",
    "            print(f\"Erro ao salvar o modelo: {e}\")\n",
    "            raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo LinearRegression treinado e salvo com sucesso!\n",
      "Modelo DecisionTree treinado e salvo com sucesso!\n",
      "Modelo XGBoost treinado e salvo com sucesso!\n",
      "Modelo RandomForest treinado e salvo com sucesso!\n",
      "Modelo Ridge treinado e salvo com sucesso!\n",
      "Modelo Lasso treinado e salvo com sucesso!\n",
      "Modelo Lasso treinado e salvo com sucesso!\n",
      "Modelo Random Forest treinado e salvo com sucesso!\n",
      "Modelo SVM treinado e salvo com sucesso!\n",
      "Modelo KNeighbors treinado e salvo com sucesso!\n",
      "Modelo LogisticRegression treinado e salvo com sucesso!\n",
      "Modelo GaussianNB treinado e salvo com sucesso!\n",
      "Modelo GaussianNB treinado e salvo com sucesso!\n"
     ]
    }
   ],
   "source": [
    "# train_and_save_model(dataset_name, model_type, algorithm, model, params={}, use_cross_val=False, test_size=0.2, val_size=0.0, cv=5, scaling = True, oversample=False, feature_selection=False, k=10)\n",
    "\n",
    "# REGRESS√ÉO\n",
    "# Hold-out\n",
    "train_and_save_model(\"diabetes\", \"regression\", \"LinearRegression\", LinearRegression(), {\"fit_intercept\": True}, test_size=0.2, val_size=0.0, scaling=True) \n",
    "\n",
    "train_and_save_model(\"diabetes\", \"regression\", \"DecisionTree\", DecisionTreeRegressor(), {\"max_depth\": 3, \"min_samples_split\": 5}, use_cross_val=False, test_size=0.2, val_size=0.1, scaling=False, feature_selection=True)\n",
    "\n",
    "train_and_save_model(\"california\", \"regression\", \"XGBoost\", XGBRegressor(), {\"n_estimators\": 50, \"max_depth\": 3, \"learning_rate\": 0.05}, use_cross_val=False, test_size=0.3, val_size=0.05, scaling=True)\n",
    "\n",
    "train_and_save_model(\"california\", \"regression\", \"RandomForest\", RandomForestRegressor(), {\"n_estimators\": 75, \"max_depth\": 4}, use_cross_val=False, test_size=0.3, scaling=False, feature_selection=True)\n",
    "\n",
    "# Cross-Validation\n",
    "train_and_save_model(\"diabetes\", \"regression\", \"Ridge\", Ridge(), {\"alpha\": 1.0}, use_cross_val=True, cv=10, scaling=True) \n",
    "\n",
    "train_and_save_model(\"california\", \"regression\", \"Lasso\", Lasso(), {\"alpha\": 0.5}, use_cross_val=True, cv=5, scaling=False, feature_selection=True) \n",
    "\n",
    "train_and_save_model(\"california\", \"regression\", \"Lasso\", Lasso(), {\"alpha\": 0.5}, use_cross_val=True, cv=5, scaling=True) \n",
    "\n",
    "\n",
    "# CLASSIFICA√á√ÉO\n",
    "# Hold-out\n",
    "train_and_save_model(\"iris\", \"classification\", \"Random Forest\", RandomForestClassifier(), {\"n_estimators\": 50, \"max_depth\": 4}, test_size=0.2, scaling=True) \n",
    "\n",
    "train_and_save_model(\"iris\", \"classification\", \"SVM\", SVC(probability=True), {\"C\": 1.0, \"kernel\": \"rbf\"}, test_size=0.3, scaling=True) \n",
    "\n",
    "train_and_save_model(\"iris\", \"classification\", \"KNeighbors\", KNeighborsClassifier(), {\"n_neighbors\": 3}, use_cross_val=False, test_size=0.3, scaling=True, oversample=False)\n",
    "\n",
    "# Cross-Validation\n",
    "train_and_save_model(\"breast_cancer\", \"classification\", \"LogisticRegression\", LogisticRegression(max_iter=1000), {\"C\": 0.1, \"solver\": 'liblinear'}, use_cross_val=True, cv=7, scaling=True) \n",
    "\n",
    "train_and_save_model(\"breast_cancer\", \"classification\", \"GaussianNB\", GaussianNB(), {}, use_cross_val=True, cv=5, feature_selection=True) \n",
    "\n",
    "train_and_save_model(\"breast_cancer\", \"classification\", \"GaussianNB\", GaussianNB(), {}, use_cross_val=True, cv=5, oversample=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Relat√≥rios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apresenta√ß√£o Geral dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>algorithm</th>\n",
       "      <th>type</th>\n",
       "      <th>dataset</th>\n",
       "      <th>preprocessing_type</th>\n",
       "      <th>strategy_type</th>\n",
       "      <th>len_data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0</td>\n",
       "      <td>breast_cancer</td>\n",
       "      <td>Scaling</td>\n",
       "      <td>Cross-Validation</td>\n",
       "      <td>[7, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>0</td>\n",
       "      <td>breast_cancer</td>\n",
       "      <td>Scaling, Feature Selection</td>\n",
       "      <td>Cross-Validation</td>\n",
       "      <td>[5, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>0</td>\n",
       "      <td>breast_cancer</td>\n",
       "      <td>Scaling, Sampling</td>\n",
       "      <td>Cross-Validation</td>\n",
       "      <td>[5, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>1</td>\n",
       "      <td>california</td>\n",
       "      <td>Scaling</td>\n",
       "      <td>Hold-out</td>\n",
       "      <td>[0.7, 0.20998062015503877, 0.09001937984496124]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>1</td>\n",
       "      <td>california</td>\n",
       "      <td>Feature Selection</td>\n",
       "      <td>Hold-out</td>\n",
       "      <td>[0.7, 0.3, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>1</td>\n",
       "      <td>california</td>\n",
       "      <td>Feature Selection</td>\n",
       "      <td>Cross-Validation</td>\n",
       "      <td>[5, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>1</td>\n",
       "      <td>california</td>\n",
       "      <td>Scaling</td>\n",
       "      <td>Cross-Validation</td>\n",
       "      <td>[5, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>1</td>\n",
       "      <td>diabetes</td>\n",
       "      <td>Scaling</td>\n",
       "      <td>Hold-out</td>\n",
       "      <td>[0.7986425339366516, 0.2013574660633484, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>1</td>\n",
       "      <td>diabetes</td>\n",
       "      <td>Feature Selection</td>\n",
       "      <td>Hold-out</td>\n",
       "      <td>[0.7986425339366516, 0.16063348416289594, 0.04...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>1</td>\n",
       "      <td>diabetes</td>\n",
       "      <td>Scaling</td>\n",
       "      <td>Cross-Validation</td>\n",
       "      <td>[10, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0</td>\n",
       "      <td>iris</td>\n",
       "      <td>Scaling</td>\n",
       "      <td>Hold-out</td>\n",
       "      <td>[0.8, 0.2, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0</td>\n",
       "      <td>iris</td>\n",
       "      <td>Scaling</td>\n",
       "      <td>Hold-out</td>\n",
       "      <td>[0.7, 0.3, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>KNeighbors</td>\n",
       "      <td>0</td>\n",
       "      <td>iris</td>\n",
       "      <td>Scaling</td>\n",
       "      <td>Hold-out</td>\n",
       "      <td>[0.7, 0.3, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             algorithm  type        dataset          preprocessing_type  \\\n",
       "0   LogisticRegression     0  breast_cancer                     Scaling   \n",
       "1           GaussianNB     0  breast_cancer  Scaling, Feature Selection   \n",
       "2           GaussianNB     0  breast_cancer           Scaling, Sampling   \n",
       "3              XGBoost     1     california                     Scaling   \n",
       "4         RandomForest     1     california           Feature Selection   \n",
       "5                Lasso     1     california           Feature Selection   \n",
       "6                Lasso     1     california                     Scaling   \n",
       "7     LinearRegression     1       diabetes                     Scaling   \n",
       "8         DecisionTree     1       diabetes           Feature Selection   \n",
       "9                Ridge     1       diabetes                     Scaling   \n",
       "10       Random Forest     0           iris                     Scaling   \n",
       "11                 SVM     0           iris                     Scaling   \n",
       "12          KNeighbors     0           iris                     Scaling   \n",
       "\n",
       "       strategy_type                                           len_data  \n",
       "0   Cross-Validation                                          [7, 0, 0]  \n",
       "1   Cross-Validation                                          [5, 0, 0]  \n",
       "2   Cross-Validation                                          [5, 0, 0]  \n",
       "3           Hold-out    [0.7, 0.20998062015503877, 0.09001937984496124]  \n",
       "4           Hold-out                                      [0.7, 0.3, 0]  \n",
       "5   Cross-Validation                                          [5, 0, 0]  \n",
       "6   Cross-Validation                                          [5, 0, 0]  \n",
       "7           Hold-out        [0.7986425339366516, 0.2013574660633484, 0]  \n",
       "8           Hold-out  [0.7986425339366516, 0.16063348416289594, 0.04...  \n",
       "9   Cross-Validation                                         [10, 0, 0]  \n",
       "10          Hold-out                                      [0.8, 0.2, 0]  \n",
       "11          Hold-out                                      [0.7, 0.3, 0]  \n",
       "12          Hold-out                                      [0.7, 0.3, 0]  "
      ]
     },
     "execution_count": 432,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fetch_models_with_strategies():\n",
    "    with engine.connect() as connection:\n",
    "        df = pd.read_sql(text(\"\"\"\n",
    "            SELECT m.algorithm, m.type,  e.dataset, ls.preprocessing_type,  ls.type AS strategy_type, ls.len_data\n",
    "            FROM LearnStrategies ls\n",
    "            JOIN Models m ON ls.model_id = m.id\n",
    "            JOIN Experiments e ON ls.model_id = e.model_id\n",
    "            ORDER BY e.dataset\n",
    "        \"\"\"), connection)\n",
    "        return df\n",
    "\n",
    "df_models_with_strategies = fetch_models_with_strategies()\n",
    "df_models_with_strategies\n",
    "\n",
    "# type = 0: Classifica√ß√£o, 1: Regress√£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>id</th>\n",
       "      <th>algorithm</th>\n",
       "      <th>type</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>diabetes</td>\n",
       "      <td>1</td>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>mse</td>\n",
       "      <td>2900.190000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>diabetes</td>\n",
       "      <td>1</td>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>rmse</td>\n",
       "      <td>53.853400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>diabetes</td>\n",
       "      <td>1</td>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>mae</td>\n",
       "      <td>42.794100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>diabetes</td>\n",
       "      <td>1</td>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>r2</td>\n",
       "      <td>0.452603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>diabetes</td>\n",
       "      <td>2</td>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>mse</td>\n",
       "      <td>3622.810000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>diabetes</td>\n",
       "      <td>2</td>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>rmse</td>\n",
       "      <td>60.189800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>diabetes</td>\n",
       "      <td>2</td>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>mae</td>\n",
       "      <td>48.699900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>diabetes</td>\n",
       "      <td>2</td>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>r2</td>\n",
       "      <td>0.362642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>california</td>\n",
       "      <td>3</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>mse</td>\n",
       "      <td>0.434417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>california</td>\n",
       "      <td>3</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>rmse</td>\n",
       "      <td>0.659103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>california</td>\n",
       "      <td>3</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>mae</td>\n",
       "      <td>0.488687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>california</td>\n",
       "      <td>3</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>r2</td>\n",
       "      <td>0.662840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>california</td>\n",
       "      <td>4</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>mse</td>\n",
       "      <td>0.516401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>california</td>\n",
       "      <td>4</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>rmse</td>\n",
       "      <td>0.718611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>california</td>\n",
       "      <td>4</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>mae</td>\n",
       "      <td>0.531847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>california</td>\n",
       "      <td>4</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>r2</td>\n",
       "      <td>0.606563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>diabetes</td>\n",
       "      <td>5</td>\n",
       "      <td>Ridge</td>\n",
       "      <td>mse</td>\n",
       "      <td>3020.860000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>diabetes</td>\n",
       "      <td>5</td>\n",
       "      <td>Ridge</td>\n",
       "      <td>rmse</td>\n",
       "      <td>54.962400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>diabetes</td>\n",
       "      <td>5</td>\n",
       "      <td>Ridge</td>\n",
       "      <td>mae</td>\n",
       "      <td>44.457800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>diabetes</td>\n",
       "      <td>5</td>\n",
       "      <td>Ridge</td>\n",
       "      <td>r2</td>\n",
       "      <td>0.490570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>california</td>\n",
       "      <td>6</td>\n",
       "      <td>Lasso</td>\n",
       "      <td>mse</td>\n",
       "      <td>0.952078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>california</td>\n",
       "      <td>6</td>\n",
       "      <td>Lasso</td>\n",
       "      <td>rmse</td>\n",
       "      <td>0.975745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>california</td>\n",
       "      <td>6</td>\n",
       "      <td>Lasso</td>\n",
       "      <td>mae</td>\n",
       "      <td>0.767992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>california</td>\n",
       "      <td>6</td>\n",
       "      <td>Lasso</td>\n",
       "      <td>r2</td>\n",
       "      <td>0.284986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>california</td>\n",
       "      <td>7</td>\n",
       "      <td>Lasso</td>\n",
       "      <td>mse</td>\n",
       "      <td>1.331690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>california</td>\n",
       "      <td>7</td>\n",
       "      <td>Lasso</td>\n",
       "      <td>rmse</td>\n",
       "      <td>1.153990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>california</td>\n",
       "      <td>7</td>\n",
       "      <td>Lasso</td>\n",
       "      <td>mae</td>\n",
       "      <td>0.911758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>california</td>\n",
       "      <td>7</td>\n",
       "      <td>Lasso</td>\n",
       "      <td>r2</td>\n",
       "      <td>-0.000103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>iris</td>\n",
       "      <td>8</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>iris</td>\n",
       "      <td>8</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>precision</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>iris</td>\n",
       "      <td>8</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>recall</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>iris</td>\n",
       "      <td>8</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>f1_score</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>iris</td>\n",
       "      <td>8</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>auc_roc</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>iris</td>\n",
       "      <td>9</td>\n",
       "      <td>SVM</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>iris</td>\n",
       "      <td>9</td>\n",
       "      <td>SVM</td>\n",
       "      <td>precision</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>iris</td>\n",
       "      <td>9</td>\n",
       "      <td>SVM</td>\n",
       "      <td>recall</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>iris</td>\n",
       "      <td>9</td>\n",
       "      <td>SVM</td>\n",
       "      <td>f1_score</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>iris</td>\n",
       "      <td>9</td>\n",
       "      <td>SVM</td>\n",
       "      <td>auc_roc</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>iris</td>\n",
       "      <td>10</td>\n",
       "      <td>KNeighbors</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>iris</td>\n",
       "      <td>10</td>\n",
       "      <td>KNeighbors</td>\n",
       "      <td>precision</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>iris</td>\n",
       "      <td>10</td>\n",
       "      <td>KNeighbors</td>\n",
       "      <td>recall</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>iris</td>\n",
       "      <td>10</td>\n",
       "      <td>KNeighbors</td>\n",
       "      <td>f1_score</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>iris</td>\n",
       "      <td>10</td>\n",
       "      <td>KNeighbors</td>\n",
       "      <td>auc_roc</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>breast_cancer</td>\n",
       "      <td>11</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.975395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>breast_cancer</td>\n",
       "      <td>11</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.975402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>breast_cancer</td>\n",
       "      <td>11</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.975395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>breast_cancer</td>\n",
       "      <td>11</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>f1_score</td>\n",
       "      <td>0.975347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>breast_cancer</td>\n",
       "      <td>11</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>auc_roc</td>\n",
       "      <td>0.994345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>breast_cancer</td>\n",
       "      <td>12</td>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.943761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>breast_cancer</td>\n",
       "      <td>12</td>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.943761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>breast_cancer</td>\n",
       "      <td>12</td>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.943761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>breast_cancer</td>\n",
       "      <td>12</td>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>f1_score</td>\n",
       "      <td>0.943761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>breast_cancer</td>\n",
       "      <td>12</td>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>auc_roc</td>\n",
       "      <td>0.982255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>breast_cancer</td>\n",
       "      <td>13</td>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.927171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>breast_cancer</td>\n",
       "      <td>13</td>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.929110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>breast_cancer</td>\n",
       "      <td>13</td>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.927171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>breast_cancer</td>\n",
       "      <td>13</td>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>f1_score</td>\n",
       "      <td>0.927088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>breast_cancer</td>\n",
       "      <td>13</td>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>auc_roc</td>\n",
       "      <td>0.987815</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          dataset  id           algorithm       type        value\n",
       "0        diabetes   1    LinearRegression        mse  2900.190000\n",
       "1        diabetes   1    LinearRegression       rmse    53.853400\n",
       "2        diabetes   1    LinearRegression        mae    42.794100\n",
       "3        diabetes   1    LinearRegression         r2     0.452603\n",
       "4        diabetes   2        DecisionTree        mse  3622.810000\n",
       "5        diabetes   2        DecisionTree       rmse    60.189800\n",
       "6        diabetes   2        DecisionTree        mae    48.699900\n",
       "7        diabetes   2        DecisionTree         r2     0.362642\n",
       "8      california   3             XGBoost        mse     0.434417\n",
       "9      california   3             XGBoost       rmse     0.659103\n",
       "10     california   3             XGBoost        mae     0.488687\n",
       "11     california   3             XGBoost         r2     0.662840\n",
       "12     california   4        RandomForest        mse     0.516401\n",
       "13     california   4        RandomForest       rmse     0.718611\n",
       "14     california   4        RandomForest        mae     0.531847\n",
       "15     california   4        RandomForest         r2     0.606563\n",
       "16       diabetes   5               Ridge        mse  3020.860000\n",
       "17       diabetes   5               Ridge       rmse    54.962400\n",
       "18       diabetes   5               Ridge        mae    44.457800\n",
       "19       diabetes   5               Ridge         r2     0.490570\n",
       "20     california   6               Lasso        mse     0.952078\n",
       "21     california   6               Lasso       rmse     0.975745\n",
       "22     california   6               Lasso        mae     0.767992\n",
       "23     california   6               Lasso         r2     0.284986\n",
       "24     california   7               Lasso        mse     1.331690\n",
       "25     california   7               Lasso       rmse     1.153990\n",
       "26     california   7               Lasso        mae     0.911758\n",
       "27     california   7               Lasso         r2    -0.000103\n",
       "28           iris   8       Random Forest   accuracy     1.000000\n",
       "29           iris   8       Random Forest  precision     1.000000\n",
       "30           iris   8       Random Forest     recall     1.000000\n",
       "31           iris   8       Random Forest   f1_score     1.000000\n",
       "32           iris   8       Random Forest    auc_roc     1.000000\n",
       "33           iris   9                 SVM   accuracy     1.000000\n",
       "34           iris   9                 SVM  precision     1.000000\n",
       "35           iris   9                 SVM     recall     1.000000\n",
       "36           iris   9                 SVM   f1_score     1.000000\n",
       "37           iris   9                 SVM    auc_roc     1.000000\n",
       "38           iris  10          KNeighbors   accuracy     1.000000\n",
       "39           iris  10          KNeighbors  precision     1.000000\n",
       "40           iris  10          KNeighbors     recall     1.000000\n",
       "41           iris  10          KNeighbors   f1_score     1.000000\n",
       "42           iris  10          KNeighbors    auc_roc     1.000000\n",
       "43  breast_cancer  11  LogisticRegression   accuracy     0.975395\n",
       "44  breast_cancer  11  LogisticRegression  precision     0.975402\n",
       "45  breast_cancer  11  LogisticRegression     recall     0.975395\n",
       "46  breast_cancer  11  LogisticRegression   f1_score     0.975347\n",
       "47  breast_cancer  11  LogisticRegression    auc_roc     0.994345\n",
       "48  breast_cancer  12          GaussianNB   accuracy     0.943761\n",
       "49  breast_cancer  12          GaussianNB  precision     0.943761\n",
       "50  breast_cancer  12          GaussianNB     recall     0.943761\n",
       "51  breast_cancer  12          GaussianNB   f1_score     0.943761\n",
       "52  breast_cancer  12          GaussianNB    auc_roc     0.982255\n",
       "53  breast_cancer  13          GaussianNB   accuracy     0.927171\n",
       "54  breast_cancer  13          GaussianNB  precision     0.929110\n",
       "55  breast_cancer  13          GaussianNB     recall     0.927171\n",
       "56  breast_cancer  13          GaussianNB   f1_score     0.927088\n",
       "57  breast_cancer  13          GaussianNB    auc_roc     0.987815"
      ]
     },
     "execution_count": 433,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fetch_results():\n",
    "    with engine.connect() as connection: \n",
    "        df = pd.read_sql(text(\"\"\"\n",
    "            SELECT e.dataset, m.id, m.algorithm, me.type, me.value \n",
    "            FROM Experiments e \n",
    "            JOIN Models m ON e.model_id = m.id\n",
    "            JOIN Metrics me ON e.id = me.experiment_id\n",
    "        \"\"\"), connection)\n",
    "\n",
    "        df_agg = df.groupby(['id','dataset', 'algorithm', 'type'])['value'].mean().reset_index()\n",
    "\n",
    "        return df\n",
    "\n",
    "\n",
    "df_results = fetch_results()\n",
    "df_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_metrics_comparison():\n",
    "    with engine.connect() as connection:\n",
    "        df = pd.read_sql(text(\"\"\"\n",
    "            SELECT m.algorithm, e.dataset, m.type AS model_type, me.type AS metric_type, me.value\n",
    "            FROM Metrics me\n",
    "            JOIN Experiments e ON me.experiment_id = e.id\n",
    "            JOIN Models m ON e.model_id = m.id\n",
    "        \"\"\"), connection)\n",
    "        \n",
    "        df['model_type'] = df['model_type'].map({0: 'Classifica√ß√£o', 1: 'Regress√£o'})\n",
    "        return df\n",
    "\n",
    "df_metrics_comparison = fetch_metrics_comparison()\n",
    "\n",
    "# Dividir em tabelas de classifica√ß√£o e regress√£o\n",
    "classification_metrics = df_metrics_comparison[df_metrics_comparison['model_type'] == 'Classifica√ß√£o']\n",
    "regression_metrics = df_metrics_comparison[df_metrics_comparison['model_type'] == 'Regress√£o']\n",
    "\n",
    "# Pivotar as tabelas para melhor visualiza√ß√£o\n",
    "classification_comparison = classification_metrics.pivot_table(index=['dataset', 'algorithm'], columns='metric_type', values='value').reset_index()\n",
    "regression_comparison = regression_metrics.pivot_table(index=['dataset', 'algorithm'], columns='metric_type', values='value').reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>metric_type</th>\n",
       "      <th>dataset</th>\n",
       "      <th>algorithm</th>\n",
       "      <th>mae</th>\n",
       "      <th>mse</th>\n",
       "      <th>r2</th>\n",
       "      <th>rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>california</td>\n",
       "      <td>Lasso</td>\n",
       "      <td>0.839875</td>\n",
       "      <td>1.141884</td>\n",
       "      <td>0.142442</td>\n",
       "      <td>1.064868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>california</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.531847</td>\n",
       "      <td>0.516401</td>\n",
       "      <td>0.606563</td>\n",
       "      <td>0.718611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>california</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.488687</td>\n",
       "      <td>0.434417</td>\n",
       "      <td>0.662840</td>\n",
       "      <td>0.659103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>diabetes</td>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>48.699900</td>\n",
       "      <td>3622.810000</td>\n",
       "      <td>0.362642</td>\n",
       "      <td>60.189800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>diabetes</td>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>42.794100</td>\n",
       "      <td>2900.190000</td>\n",
       "      <td>0.452603</td>\n",
       "      <td>53.853400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>diabetes</td>\n",
       "      <td>Ridge</td>\n",
       "      <td>44.457800</td>\n",
       "      <td>3020.860000</td>\n",
       "      <td>0.490570</td>\n",
       "      <td>54.962400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "metric_type     dataset         algorithm        mae          mse        r2  \\\n",
       "0            california             Lasso   0.839875     1.141884  0.142442   \n",
       "1            california      RandomForest   0.531847     0.516401  0.606563   \n",
       "2            california           XGBoost   0.488687     0.434417  0.662840   \n",
       "3              diabetes      DecisionTree  48.699900  3622.810000  0.362642   \n",
       "4              diabetes  LinearRegression  42.794100  2900.190000  0.452603   \n",
       "5              diabetes             Ridge  44.457800  3020.860000  0.490570   \n",
       "\n",
       "metric_type       rmse  \n",
       "0             1.064868  \n",
       "1             0.718611  \n",
       "2             0.659103  \n",
       "3            60.189800  \n",
       "4            53.853400  \n",
       "5            54.962400  "
      ]
     },
     "execution_count": 435,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regression_comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>metric_type</th>\n",
       "      <th>dataset</th>\n",
       "      <th>algorithm</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>auc_roc</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>breast_cancer</td>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>0.935466</td>\n",
       "      <td>0.985035</td>\n",
       "      <td>0.935424</td>\n",
       "      <td>0.936435</td>\n",
       "      <td>0.935466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>breast_cancer</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.975395</td>\n",
       "      <td>0.994345</td>\n",
       "      <td>0.975347</td>\n",
       "      <td>0.975402</td>\n",
       "      <td>0.975395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>iris</td>\n",
       "      <td>KNeighbors</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>iris</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>iris</td>\n",
       "      <td>SVM</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "metric_type        dataset           algorithm  accuracy   auc_roc  f1_score  \\\n",
       "0            breast_cancer          GaussianNB  0.935466  0.985035  0.935424   \n",
       "1            breast_cancer  LogisticRegression  0.975395  0.994345  0.975347   \n",
       "2                     iris          KNeighbors  1.000000  1.000000  1.000000   \n",
       "3                     iris       Random Forest  1.000000  1.000000  1.000000   \n",
       "4                     iris                 SVM  1.000000  1.000000  1.000000   \n",
       "\n",
       "metric_type  precision    recall  \n",
       "0             0.936435  0.935466  \n",
       "1             0.975402  0.975395  \n",
       "2             1.000000  1.000000  \n",
       "3             1.000000  1.000000  \n",
       "4             1.000000  1.000000  "
      ]
     },
     "execution_count": 436,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hiperpar√¢metros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "breast_cancer (LogisticRegression) : { C = 0.1; solver = liblinear }\n",
      "california (Lasso) : { alpha = 0.5; alpha = 0.5 }\n",
      "california (RandomForest) : { n_estimators = 75; max_depth = 4 }\n",
      "california (XGBoost) : { n_estimators = 50; max_depth = 3; learning_rate = 0.05 }\n",
      "diabetes (DecisionTree) : { max_depth = 3; min_samples_split = 5 }\n",
      "diabetes (LinearRegression) : { fit_intercept = True }\n",
      "diabetes (Ridge) : { alpha = 1.0 }\n",
      "iris (KNeighbors) : { n_neighbors = 3 }\n",
      "iris (Random Forest) : { n_estimators = 50; max_depth = 4 }\n",
      "iris (SVM) : { C = 1.0; kernel = rbf }\n"
     ]
    }
   ],
   "source": [
    "# Fun√ß√£o para buscar modelos e hiperpar√¢metros\n",
    "def fetch_models_and_hyperparams():\n",
    "    # Conectar ao banco de dados usando SQLAlchemy\n",
    "    with engine.connect() as connection:\n",
    "        # Executar consulta SQL para buscar datasets, algoritmos e hiperpar√¢metros\n",
    "        df = pd.read_sql(text(\"\"\"\n",
    "            SELECT e.dataset, m.algorithm, h.name AS hyperparameter_name, h.value AS hyperparameter_value\n",
    "            FROM Experiments e\n",
    "            JOIN Models m ON e.model_id = m.id\n",
    "            JOIN Hyperparameters h ON m.id = h.model_id\n",
    "        \"\"\"), connection)\n",
    "\n",
    "        # Inicializar dicion√°rio para armazenar resultados\n",
    "        results = {}\n",
    "        # Agrupar resultados por dataset e algoritmo\n",
    "        for (dataset, algorithm), group in df.groupby(['dataset', 'algorithm']):\n",
    "            # Concatenar hiperpar√¢metros em uma string\n",
    "            hyperparams = \"; \".join(f\"{row['hyperparameter_name']} = {row['hyperparameter_value']}\" for _, row in group.iterrows())\n",
    "            # Armazenar hiperpar√¢metros no dicion√°rio de resultados\n",
    "            results[f\"{dataset} ({algorithm})\"] = f\"{{ {hyperparams} }}\"\n",
    "\n",
    "        return results\n",
    "\n",
    "# Buscar modelos e hiperpar√¢metros e armazenar em uma vari√°vel\n",
    "models_and_hyperparams = fetch_models_and_hyperparams()\n",
    "\n",
    "# Imprimir resultados\n",
    "for model, hyperparams in models_and_hyperparams.items():\n",
    "    print(f\"{model} : {hyperparams}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Gerar Relat√≥rio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relat√≥rio HTML gerado com sucesso!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Gerar relat√≥rio HTML dos resultados\n",
    "# Criar diret√≥rio para armazenar relat√≥rios, se n√£o existir\n",
    "os.makedirs(\"reports\", exist_ok=True)\n",
    "\n",
    "# Gerar um nome de arquivo √∫nico para o relat√≥rio\n",
    "def generate_unique_filename(base_name, extension=\".html\"):\n",
    "    counter = 1\n",
    "    filename = f\"{base_name}{extension}\"\n",
    "    while os.path.exists(os.path.join(\"reports\", filename)):\n",
    "        filename = f\"{base_name}_{counter}{extension}\"\n",
    "        counter += 1\n",
    "    return filename\n",
    "\n",
    "# Gerar nome de arquivo √∫nico para o relat√≥rio atual\n",
    "report_filename = generate_unique_filename(\"report_models\")\n",
    "\n",
    "def fetch_models():\n",
    "    with engine.connect() as connection:\n",
    "        df = pd.read_sql(text(\"SELECT * FROM Models\"), connection)\n",
    "        return df\n",
    "\n",
    "def fetch_hyperparameters():\n",
    "    with engine.connect() as connection:\n",
    "        df = pd.read_sql(text(\"SELECT * FROM Hyperparameters\"), connection)\n",
    "        return df\n",
    "\n",
    "def fetch_learn_strategies():\n",
    "    with engine.connect() as connection:\n",
    "        df = pd.read_sql(text(\"SELECT * FROM LearnStrategies\"), connection)\n",
    "        return df\n",
    "\n",
    "def fetch_experiments():\n",
    "    with engine.connect() as connection:\n",
    "        df = pd.read_sql(text(\"SELECT * FROM Experiments\"), connection)\n",
    "        return df\n",
    "\n",
    "def fetch_metrics():\n",
    "    with engine.connect() as connection:\n",
    "        df = pd.read_sql(text(\"SELECT * FROM Metrics\"), connection)\n",
    "        return df\n",
    "\n",
    "def generate_html_report():\n",
    "    models = fetch_models()\n",
    "    hyperparameters = fetch_hyperparameters()\n",
    "    learn_strategies = fetch_learn_strategies()\n",
    "    experiments = fetch_experiments()\n",
    "    metrics = fetch_metrics()\n",
    "\n",
    "    # Estilo CSS para o relat√≥rio\n",
    "    css_styles = \"\"\"\n",
    "    <style>\n",
    "        body { font-family: Arial, sans-serif; margin: 40px; padding: 20px; background-color: #f4f4f4; }\n",
    "        h1 { text-align: center; color: #333; }\n",
    "        h2 { border-bottom: 2px solid #2F4156; padding-bottom: 5px; color: #2F4156; }\n",
    "        .container { max-width: 900px; margin: auto; background: white; padding: 20px; border-radius: 8px; box-shadow: 0px 0px 10px rgba(0,0,0,0.1); }\n",
    "        table { width: 100%; border-collapse: collapse; margin-top: 10px; }\n",
    "        th, td { padding: 10px; border: 1px solid #ddd; text-align: left; }\n",
    "        th { background-color: #2F4156; color: white; }\n",
    "        .hyperparams { font-style: italic; color: #555; }\n",
    "        hr { border: 0; height: 1px; background: #ddd; margin: 20px 0; }\n",
    "    </style>\n",
    "    \"\"\"\n",
    "\n",
    "    # In√≠cio do HTML\n",
    "    html_content = f\"\"\"\n",
    "    <html>\n",
    "    <head>\n",
    "        <title>Relat√≥rio de Modelos</title>\n",
    "        {css_styles}\n",
    "    </head>\n",
    "    <body>\n",
    "        <div class='container'>\n",
    "            <h1>Relat√≥rio de Modelos</h1>\n",
    "    \"\"\"\n",
    "\n",
    "    # Agrupar modelos por dataset\n",
    "    grouped_experiments = experiments.groupby('dataset')\n",
    "\n",
    "    for dataset, group in grouped_experiments:\n",
    "        html_content += f\"<h2>Dataset: {dataset}</h2>\"\n",
    "\n",
    "        for _, experiment in group.iterrows():\n",
    "            model_id = experiment['model_id']\n",
    "            model = models[models['id'] == model_id].iloc[0]\n",
    "            algorithm = model['algorithm']\n",
    "            model_type = \"Classifica√ß√£o\" if model['type'] == 0 else \"Regress√£o\"\n",
    "\n",
    "            html_content += f\"\"\"\n",
    "                <h3>Modelo: {algorithm}</h3>\n",
    "                <p><strong>Tipo:</strong> {model_type}</p>\n",
    "            \"\"\"\n",
    "\n",
    "            # Adicionar hiperpar√¢metros\n",
    "            model_hyperparams = hyperparameters[hyperparameters['model_id'] == model_id]\n",
    "            if not model_hyperparams.empty:\n",
    "                html_content += \"<h4>Hiperpar√¢metros:</h4><ul>\"\n",
    "                for _, param in model_hyperparams.iterrows():\n",
    "                    html_content += f\"<li>{param['name']} = {param['value']}</li>\"\n",
    "                html_content += \"</ul>\"\n",
    "\n",
    "            # Adicionar estrat√©gias de aprendizado\n",
    "            model_strategies = learn_strategies[learn_strategies['model_id'] == model_id]\n",
    "            if not model_strategies.empty:\n",
    "                html_content += \"<h4>Estrat√©gias de Aprendizado:</h4><ul>\"\n",
    "                for _, strategy in model_strategies.iterrows():\n",
    "                    html_content += f\"<li>{strategy['preprocessing_type']} - {strategy['data_sampling']} - {strategy['type']} - {strategy['len_data']}</li>\"\n",
    "                html_content += \"</ul>\"\n",
    "\n",
    "            # Adicionar m√©tricas\n",
    "            model_metrics = metrics[metrics['experiment_id'] == experiment['id']]\n",
    "            if not model_metrics.empty:\n",
    "                html_content += \"<h4>M√©tricas:</h4><ul>\"\n",
    "                for _, metric in model_metrics.iterrows():\n",
    "                    html_content += f\"<li>{metric['type']} = {metric['value']}</li>\"\n",
    "                html_content += \"</ul>\"\n",
    "\n",
    "            html_content += \"<hr>\"\n",
    "\n",
    "    # Fechando o HTML\n",
    "    html_content += \"\"\"\n",
    "        </div>\n",
    "    </body>\n",
    "    </html>\n",
    "    \"\"\"\n",
    "\n",
    "    with open(f\"reports/{report_filename}\", \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(html_content)\n",
    "\n",
    "generate_html_report()\n",
    "print(\"Relat√≥rio HTML gerado com sucesso!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conex√£o com o banco de dados encerrada.\n"
     ]
    }
   ],
   "source": [
    "engine.dispose()\n",
    "print(\"Conex√£o com o banco de dados encerrada.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
